---
title: "blup"
author: "Chen Guo-Bo [chenguobo@gmail.com]"
date: "`r Sys.Date()`"
output:
 html_document:
    theme: united
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Table of contents {.tabset .tabset-fade .tabset-pills}
```{r}
print(Sys.time())
set.seed(2020)
```

## 1 LMM (BLUE & BLUP)
$$\mathbf{y}=\mathbf{\color{red}{X\beta}+\color{blue}{\sum_{k=1}^KZ_ku_k}+\color{green}{e}}$$

Design matrices (or incident matrices):

$\color{red}{\mathbf{X}}$ ($n\times p$) for fixed effects vector $\color{red}{\mathbf{\beta}}$

$\mathbf{Z_k}$ ($n\times q_k$) for random effects vector $\mathbf{u_k}$, and $u_k \sim N(0, \mathbf{G_k})$. For example, if $u_k$ is sampled from iid with variance $\sigma^2_k$, then $u_k \sim N(0, \mathbf{I}\sigma^2_k)$.

$\color{green}{\mathbf{e}}$ is random effects. Often, for unrelated samples, $e \sim N(0, \mathbf{I}\sigma^2_e)$.

Then $\mathbf{y}$ follows the distribution $$MVN(\color{red}{\mathbf{X\beta}}, V=\color{blue}{\sum_{k=1}^KG_k\sigma^2_k+R\sigma^2_e})$$

### Estimator
Using general least squares estimation

$$\mathbf{\color{red}{\hat{\beta}}=(X^TV^{-1}X)^{-1}X^TV^{-1}y}$$
Of note, when $V=I$, it becomes ordinary LSE that $\mathbf{\hat{\beta}=(X^TX)^{-1}X^Ty}$.

The random effect is estimated, known as $\color{cyan}{\boxed{BLUP}}$, can be written as
$$\mathbf{\color{blue}{\hat{u}_k}=G_kZ^T_kV^{-1}(y-X\hat{\beta})}$$

Given $\mathbf{\hat{\beta}}$ and $\hat{\mathbf{u}}$ we have
$$
\mathbf{E}=\left \{
\left [ \begin{array}{l}
\mathbf{\beta}-\mathbf{\hat{\beta}}\\
\mathbf{\mu}-\mathbf{\hat{\mu}}
\end{array}
\right ]
\left [ \begin{array}{l}
\mathbf{\beta}-\mathbf{\hat{\beta}}\\
\mathbf{\mu}-\mathbf{\hat{\mu}}
\end{array}
\right ]^T
\right \}=
\begin{bmatrix}
\mathbf{X^TR^{-1}X} & \mathbf{X^TR^{-1}Z}\\
\mathbf{Z^TR^{-1}X} & \mathbf{X^TR^{-1}Z}+\mathbf{G}^{-1}\\
\end{bmatrix}^{-1}\sigma^2_e
$$

## 2 Mixed model equation (MME)
MME is proposed by Henderson. Here we follow the summary by Robinson (Statistical Science, 1991, 6:15-32),

The joint density of $y$ and $u$ is
$$
(2\pi\sigma^2_e)^{-\frac{1}{2}n-\frac{1}{2}q}
\lgroup det
\begin{bmatrix}
\mathbf{G_1} & 0 & 0\\
0 & \mathbf{G_2} & 0 \\
0 & 0 & \mathbf{R}\\
\end{bmatrix}
\rgroup
^{-1}
\cdot
exp
\left \{
-\frac{1}{2\sigma^2_e}
\begin{bmatrix}
\mathbf{u_1}\\
\mathbf{u_2}\\
\mathbf{y-X\beta-Z_1u_1-Z_2u_2}
\end{bmatrix}^T
\begin{bmatrix}
\mathbf{G_1} & 0 &0\\
0 & \mathbf{G_2} & 0\\
0 & 0 &\mathbf{R} \\
\end{bmatrix}^{-1}
\begin{bmatrix}
\mathbf{u_1}\\
\mathbf{u_2}\\
\mathbf{y-X\beta-Z_1u_1-Z_2u_2}
\end{bmatrix}
\right \}
$$
We can define

$$\mathbf{\mathcal{Q}}=\mathbf{u_1^TG_1^{-1}u_1}+\mathbf{u_2^TG_2^{-1}u_2}+\mathbf{\tilde{y}R^{-1}\tilde{y}}$$

in which $\mathbf{\tilde{y}}=\mathbf{y-X\beta-Z_1u_1-Z_2u_2}$,

$$
\begin{bmatrix}
\mathbf{\frac{\partial\mathcal{Q}}{\partial\beta}}=-2\mathbf{X\tilde{y}+2X^T\beta X+2Z_1^Tu_1Z_1+2Z_2^Tu_2Z_2}=0\\
\mathbf{\frac{\partial\mathcal{Q}}{\partial u_1}}=2\mathbf{G_1^{-1}u_1-2yZ_1+2X\beta Z_1+2Z_1^Tu_1Z_1+2Z_1^Tu_2Z_2}=0\\
\mathbf{\frac{\partial\mathcal{Q}}{\partial u_2}}=2\mathbf{G_2^{-1}u_2-2yZ_2+2X\beta Z_2+2Z_1^Tu_1Z_2+2Z_2^Tu_2Z_2}=0
\end{bmatrix}
$$

It yields MME equation below

$$
\begin{bmatrix}
\mathbf{X^TR^{-1}X} & \mathbf{X^TR^{-1}Z_1} & \mathbf{X^TR^{-1}Z_2} \\
\mathbf{Z_1^TR^{-1}X} & \mathbf{Z_1^TR^{-1}Z_1}+\mathbf{G_1^{-1}} & \mathbf{Z_1^TR^{-1}Z_2}\\
\mathbf{Z_2^TR^{-1}X} & \mathbf{Z_2^TR^{-1}Z_1} & \mathbf{Z_2^TR^{-1}Z_2}+\mathbf{G_2^{-1}}
\end{bmatrix}
\begin{bmatrix}
\mathbf{\hat{\beta}}\\
\mathbf{\hat{u}_1}\\
\mathbf{\hat{u}_2}
\end{bmatrix}
=
\begin{bmatrix}
\mathbf{X^TR^{-1}y}\\
\mathbf{Z_1^TR^{-1}y}\\
\mathbf{Z_2^TR^{-1}y}\\
\end{bmatrix}
$$
When $R=I$, it can be written as

$$
\begin{bmatrix}
\mathbf{X^TX} & \mathbf{X^TZ_1} & \mathbf{X^TZ_2} \\
\mathbf{Z_1^TX} & \mathbf{Z_1^TZ_1}+\lambda_1\mathbf{G_1^{-1}} & \mathbf{Z_1^TZ_2}\\
\mathbf{Z_2^TR^{-1}X} & \mathbf{Z_2^TR^{-1}Z_1} & \mathbf{Z_2^TR^{-1}Z_2}+\lambda_2\mathbf{G_2^{-1}}
\end{bmatrix}
\begin{bmatrix}
\mathbf{\hat{\beta}}\\
\mathbf{\hat{u}_1}\\
\mathbf{\hat{u}_2}
\end{bmatrix}
=
\begin{bmatrix}
\mathbf{X^Ty}\\
\mathbf{Z_1^Ty}\\
\mathbf{Z_2^Ty}\\
\end{bmatrix}
$$
in which $\lambda_1=\sigma^2_e/\sigma^2_1$ and $\lambda_2=\sigma^2_e/\sigma^2_2$.

## Walsh'sCh26 example 1

$$\mathbf{y}=
\begin{bmatrix}
y_{\color{blue}{1},\color{red}{1},1}\\
y_{\color{blue}{1},\color{red}{2},1}\\
y_{\color{blue}{2},\color{red}{1},1}\\
y_{\color{blue}{2},\color{red}{1},2}\\
y_{\color{blue}{3},\color{red}{1},1}\\
y_{\color{blue}{3},\color{red}{2},1}\\
\end{bmatrix}
=
\begin{bmatrix}
9\\
12\\
11\\
6\\
7\\
14
\end{bmatrix}
$$
giving the mixed model as
$$\mathbf{y=X\beta+Zu+e}$$
the incident matrix is 
$$
\color{red}{\mathbf{X}=
\begin{bmatrix}
1 & 0\\
0 & 1\\
1 & 0 \\
1 & 0 \\
1 & 0 \\
0 & 1 \\
\end{bmatrix}}
$$
and $\mathbf{\beta}^T=(\beta_1, \beta_2)$
$$
\color{blue}{\mathbf{Z}=
\begin{bmatrix}
1 & 0 & 0\\
1 & 0 & 0\\
0 & 1 & 0\\
0 & 1 & 0\\
0 & 0 & 1 \\
0 & 0 & 1 \\
\end{bmatrix}}
$$
and $\mathbf{u}^T=(u_1, u_2, u_3)$.

```{r, walsh example1}

#walsh example
y=matrix(c(9, 12, 11, 6, 7, 14), 6, 1)
x=matrix(0, 6, 2)
x[,1]=c(1, 0, 1, 1, 1, 0)
x[,2]=c(0, 1, 0, 0, 0, 1)
z=matrix(0, 6, 3)
z[,1]=c(1,1,0,0,0,0)
z[,2]=c(0,0,1,1,0,0)
z[,3]=c(0,0,0,0,1,1)
Se=6
Sa=2
V=Sa*z%*%diag(1, 3, 3)%*%t(z)+Se*diag(1, 6, 6)
VI=solve(V)

bL=solve(t(x)%*%VI%*%x)%*%t(x)%*%VI%*%y
bS=Sa*diag(1, 3, 3)%*%t(z)%*%VI%*%(y-x%*%bL)

#MME
R=diag(Se, 6, 6)
RI=solve(R)
c11=t(x)%*%RI%*%x
c12=t(x)%*%RI%*%z
c21=t(c12)
c22=solve(Sa*diag(1, 3, 3))+t(z)%*%RI%*%z
MME_m=rbind(cbind(c11, c12), cbind(c21, c22))
MME_y=rbind(t(x)%*%RI%*%y, t(z)%*%RI%*%y)

MME_b=solve(MME_m)%*%MME_y
plot(bL, MME_b[1:2,1])
abline(a=0, b=1, col="red")
plot(bS, MME_b[3:5,1])
abline(a=0, b=1, col="red")

```

## blup1 animal model
```{r, blup-animal}
Ml=20
Ms=100
N=1000

Xl=apply(matrix(rbinom(Ml*N, 2, 0.5), N, Ml), 2, scale)
Gl=Xl%*%t(Xl)/Ml
Xs=apply(matrix(rbinom(Ms*N, 2, 0.5), N, Ms), 2, scale)
Gs=Xs%*%t(Xs)/Ms

hs=0.5
hsQ=hs/(2*0.5*0.5*Ms)
he=1
bl=rnorm(Ml, 1)
bs=rnorm(Ms, 0, sqrt(hs/(2*0.5*0.5*Ms)))

Fb=Xl%*%bl
Sb=Xs%*%bs
Ev=rnorm(N, 0, sqrt(he))
y=Fb+Sb+Ev

V=Gs*hs+diag(he, N, N)
V_Inv=solve(V)

layout(matrix(1:6, 2, 3, byrow = T))
bl_est=solve(t(Xl)%*%V_Inv%*%Xl)%*%t(Xl)%*%V_Inv%*%y
plot(bl, bl_est, pch=16, cex=1.5, col="green")
abline(a=0, b=1, col="red")
ypre=y-Xl%*%bl_est

bs_est=hs/Ms*t(Xs)%*%V_Inv%*%ypre
plot(bs, bs_est, pch=16, cex=1.5, col="green")
abline(a=0, b=1, col="red")

gs_est=hs/Ms*Xs%*%t(Xs)%*%V_Inv%*%ypre
plot(Sb, gs_est, pch=16, cex=0.5,col="green")
abline(a=0, b=1, col="red")

####MME
Ehe=var(Ev)
c11=t(Xl)%*%Xl
c12=t(Xl)%*%Xs
c21=t(c12)
c22_I=t(Xs)%*%Xs
c22=c22_I+solve(diag(1, Ms, Ms))*he/(hs/Ms)

Y1=t(Xl)%*%y
Y2=t(Xs)%*%y

M1=cbind(c11, c12)
M2=cbind(c21, c22)

MMe_mat=rbind(cbind(c11, c12), cbind(c21, c22))
MMe_y=rbind(Y1, Y2)
bMMe=solve(MMe_mat)%*%MMe_y

plot(bl, bMMe[1:Ml], pch=16, col="blue")
abline(a=0, b=1, col="red")
plot(bs, bMMe[(Ml+1):(Ms+Ml)], col="blue")
abline(a=0, b=1, col="red")
plot(bs_est, bMMe[(Ml+1):(Ms+Ml)], col="blue")
abline(a=0, b=1, col="red")

```

## ADD+Dom
Eq 26.21, 26.22, 26.23
```{r, AD}
M=200
N=200
ha=0.5
hd=0.3

frq=rep(0.5, M)
G=matrix(rbinom(M*N, 2, frq), N, M)
Gd=matrix(ifelse(G==1, 1, 0), N, M)
a=rnorm(M)
d=rnorm(M)
BVa=G%*%a
BVd=Gd%*%d

Beta=matrix(c(1, 2), 2, 1)
X=matrix(rbinom(2*N, 2, 0.5), N, 2)
vBVa=var(BVa)[1,1]
vBVd=var(BVd)[1,1]
ve=vBVa+vBVd
y=X%*%Beta+BVa+BVd+rnorm(N, 0, sqrt(ve))

#MME
C11=t(X)%*%X
C12=t(X)
C21=X
C13=t(X)
C31=X
C22=diag(1, M)+1.5*diag(1, M)
C33=diag(1, M)+3*diag(1, M)
MME_1=cbind(C11, C12, C13)
MME_2=cbind(C21, C22, diag(1, M))
MME_3=cbind(C31, diag(1, M), C33)

MME_mat=rbind(MME_1, MME_2, MME_3)
MME_y=matrix(c(t(X)%*%y, y, y), 2*M+2, 1)
MME_b=solve(MME_mat)%*%MME_y
plot(BVa, MME_b[3:(M+2),1])
abline(a=0, b=1)
plot(BVd, MME_b[(M+3):(nrow(MME_b)),1])

##GLMM
V=(diag(vBVa, N)+diag(vBVd, N)+diag(ve, N))
VI=solve(V)
bEst=solve(t(X)%*%VI%*%X)%*%t(X)%*%VI%*%y

uA=vBVa*VI%*%(y-X%*%bEst)
uD=vBVd*VI%*%(y-X%*%bEst)
uD2=(vBVd/vBVa)*uA

plot(uA, MME_b[3:(M+2),1])
abline(a=0, b=1, col="red")
plot(uD, MME_b[(M+3):(nrow(MME_b)),1])
abline(a=0, b=1, col="red")
plot(uD, uD2)
abline(a=0, b=1, col="red")

```


## Simulation setup
```{r simu-setup}
library(Rcpp)
sourceCpp("~/git/Notes/R/RLib/Shotgun.cpp") #https://github.com/gc5k/Notes/blob/master/R/RLib/Shotgun.cpp
###############simulation setup
hl=0.2 #large effect
hs=0.3 #small effect
BLK=20 #number of blocks
BLK_snp=50 #LD block size

M=BLK_snp*BLK #loci
Bloci=seq(10, M, by=BLK) #big effect loci
Ml=length(Bloci) #one large effect in each block
Ms=M-Ml #number of small effect loci

ldInterval=BLK_snp*seq(0, BLK) #ld Tag
frq=runif(M, 0.1, 0.9) #allele frequency
Dp=runif(M-1, 0.8, 1)*sample(c(1,-1), M-1, replace = T) #ld
Dp[BLK_snp*seq(1,BLK-1)]=0 #set break
N=1000 #sample size
Nref=1000 #test

```

## Simulation training and refpop
```{r pop}
####################
#simulating effect
####################
snpEff=array(0, M)
snpEff[-Bloci]=rnorm(Ms, 0, sqrt(hs/Ms))
print(var(snpEff[-Bloci])*Ms)
snpEff[Bloci]=rnorm(Bloci, 0, sqrt(hl/Ml))
print(var(snpEff[Bloci])*Ml)

####################
#simulating genotype
####################
G=GenerateGenoDprimeRcpp(frq, Dp, N)
sG=scale(G) #scale genotype

#simulating additive effect
bv=sG%*%snpEff
ve=var(bv)/(hl+hs)*(1-hl-hs) #scale residual
y=bv+rnorm(N,0, sqrt(ve))

#simulating reference genome for ld block
Gref=GenerateGenoDprimeRcpp(frq, Dp, Nref)
sGref=scale(Gref)


```


## GWAS
```{r gwas}
#########################
#GWAS
#########################
SumStat=matrix(0, M, 4) #summary stats
for(i in 1:nrow(SumStat)) {
  mod=lm(y~sG[,i])
  SumStat[i,]=summary(mod)$coefficient[2,]
}

#####select big loci
BigLoci=Bloci #can be other procedure to pick up big effect loci


```

## Henderson blup

```{r hblup}
##########################################
##Henderson's MME, computational expensive
##########################################
TH_1=Sys.time()
h2_hat=hs+hl #can be estimated wiht other methods. Here we direct plug in the true h2
hs_hat=hs/Ms #h2 for each locus
sGl=sG[,-BigLoci] #matrix for small effect
lGl=sG[,BigLoci] #matrix for large effect

H=hs_hat*sGl%*%t(sGl)+diag(1,N) #Big V matrix
H_inv=solve(H) #inverse it

m1=t(lGl)%*%H_inv%*%lGl
m1_inv=solve(m1)
Bl_henderson=m1_inv%*%t(lGl)%*%H_inv%*%y #generalized estimation for fixed effect

y_res=y-lGl%*%Bl_henderson #residual
Bs_henderson=hs_hat*t(sGl)%*%H_inv%*%(y_res) #blup for random snp effects
TH_2=Sys.time()
print(TH_2-TH_1)

##plot results
layout(matrix(1:6,2,3, byrow = T))
plot(snpEff, SumStat[,1], col="red", pch=16, cex=0.5, xlab="B", ylab="LSE-B")
points(snpEff[BigLoci], SumStat[BigLoci,1], col="blue", pch=2)
abline(a=0, b=1, col="red")

plot(snpEff[-BigLoci], Bs_henderson, col="gold", pch=5, cex=0.5, xlab="Bsmall", ylab="BLUP-Bsmall")
abline(a=0, b=1, col="red")

plot(snpEff[BigLoci], Bl_henderson, col="green", pch=15, xlab="Blarge", ylab="Blarge-blup")
abline(a=0, b=1, col="red")

hist(snpEff[BigLoci], main="B")
hist(SumStat[BigLoci], main="Blup-Bsmall")
hist(Bs_henderson[BigLoci], main="Blup-Blarge")


```

## zBLUP
```{r zBLUP}
########################################
#zxBLUP AJHG v106 p679-693
########################################
LDmatOrg=t(sG)%*%sG/(N-1)

ZH_1=Sys.time()
Ns=ceiling(Nref*1)
subS=sort(sample(Nref, Ns)) #subsampling technique
LDmat=t(sGref[subS,])%*%sGref[subS,]/(Ns-1)

#LDmat=LDmatOrg
ZH_1_1=Sys.time()

hMat=matrix(0, M-length(BigLoci), M-length(BigLoci)) #v matrix
lCnt=0
ldSS_size=matrix(0, BLK, 2)
for(i in 1:BLK) { #block-wise inversion for V using Zhou Xiang's trick
  ld_tag=seq(ldInterval[i]+1, ldInterval[i+1])
  rmLoci=intersect(ld_tag, Bloci)
  if(length(rmLoci)!=0) {
    ld_tag=setdiff(ld_tag, rmLoci)
  }
  ldss=LDmat[ld_tag, ld_tag]
  Ims_sub=diag(1/hs_hat/N, length(ld_tag))
  h=Ims_sub+ldss
  h_Inv=solve(h)
  hMat[(lCnt+1):(lCnt+length(ld_tag)), (lCnt+1):(lCnt+length(ld_tag))]=h_Inv
  ldSS_size[i,]=c(lCnt+1, lCnt+length(ld_tag))
  lCnt=lCnt+length(ld_tag)
}
LDll=LDmat[BigLoci, BigLoci]
LDls=LDmat[BigLoci, -BigLoci]
LDsl=LDmat[-BigLoci, BigLoci]
LDss=LDmat[-BigLoci, -BigLoci]
Zl=SumStat[BigLoci, 3]
Zs=SumStat[-BigLoci, 3]

P1=LDls%*%hMat #there is another trick here to reduce multiplication
C1=(LDll-P1%*%LDsl)
C1_inv=solve(C1)
C2=(Zl-P1%*%Zs)
beta_l_zx=1/sqrt(N)*C1_inv%*%C2

Ims=diag(1, M-length(BigLoci))

ZH_2_1=Sys.time()
P2=matrix(0, nrow(hMat), ncol(hMat))
for(i in 1:nrow(ldSS_size)) {
  l1=ldSS_size[i,1]
  l2=ldSS_size[i,2]
  P2[l1:l2, l1:l2] = LDss[l1:l2, l1:l2] %*% hMat[l1:l2, l1:l2]
}
#P2=LDss%*%hMat
ZH_2_2=Sys.time()

beta_s_zx=hs_hat*(Ims-P2)%*%(sqrt(N)*Zs-N*LDsl%*%beta_l_zx)
ZH_3=Sys.time()

##plot
layout(matrix(1:3, 1,3))
plot(snpEff[BigLoci], beta_l_zx, ylab="Quick Big Effect", xlab="True Big effect")
abline(a=0, b=c(1))
plot(snpEff[-BigLoci], beta_s_zx, ylab="Quick small effect", xlab="True small effect")
abline(a=0, b=c(1))
plot(Bs_henderson, beta_s_zx, xlab="Henderson BLUP", ylab="Quick BLUP")
abline(a=0, b=c(1))

```

## Evalutation

```{r test}
#######################
##prediction accuracy
#######################
SIMU=30
Nt=1000
Gt=GenerateGenoDprimeRcpp(frq, Dp, Nt)
sGt=scale(Gt) #scale genotype

bvt=sGt%*%snpEff
vet=var(bvt)/(hl+hs)*(1-hl-hs) #scale residual

accuracy=matrix(0, SIMU, 3)
for(s in 1:SIMU) {
  yt=bvt+rnorm(Nt,0, sqrt(vet))

  yPre_zx=sGt[,BigLoci]%*%beta_l_zx+sGt[,-BigLoci]%*%beta_s_zx
  yPre_h=sGt[,BigLoci]%*%Bl_henderson+sGt[,-BigLoci]%*%Bs_henderson
  yPre_lse=sGt[,BigLoci]%*%SumStat[BigLoci,1]+sGt[,-BigLoci]%*%SumStat[-BigLoci,1]
  accuracy[s,1]=cor(yt, yPre_zx)
  accuracy[s,2]=cor(yt, yPre_h)
  accuracy[s,3]=cor(yt, yPre_lse)
}
barplot(colMeans(accuracy))


```

